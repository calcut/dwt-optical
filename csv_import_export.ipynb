{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5_helpers as h5\n",
    "import dummydata\n",
    "from IPython.display import display\n",
    "\n",
    "filename = 'test.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dummy Data for all elements into the HDF5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating Dummy h5 file with the following settings\")\n",
    "run_settings = dummydata.defaults\n",
    "display(run_settings)\n",
    "dummydata.fill_hdf(run_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of csv spectrometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dir = \"/Users/calum/git/Glasgow/sampleData/Beer x Bitter\"\n",
    "testfile = \"HAN24_Sensor10_BeerBitter1_Rotation1.txt\"\n",
    "df = pd.read_csv(os.path.join(dir, testfile), sep='\\t')\n",
    "\n",
    "#label columns\n",
    "reps = len(df.columns)-1\n",
    "col_names = ['wavelength']\n",
    "for r in range(reps):\n",
    "\tcol_names.append(F\"rep{r+1}\")\n",
    "df.columns = col_names\n",
    "\n",
    "# datafile = 'dataframe'\n",
    "\n",
    "# # compression_options = dict(method='zip', archive_name=f'{datafile}.csv')\n",
    "# df.to_csv(f'{datafile}.csv', index=False, sep='\\t')\n",
    "# df2 = pd.read_csv(\"dataframe.csv\", sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, file exists: ./raw/211102-HAN24-beer-A02.tsv, appending columns\n",
      "Warning, 211102-HAN24-beer-A02 already exists in ./index.tsv, updating rep count to 15\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import csv_helpers as csv\n",
    "\n",
    "dummy_metadata = {\n",
    "    'sensor'            : 'HAN24',\n",
    "    'element'           : 'A02',\n",
    "    'fluid'             : 'beer',\n",
    "}\n",
    "\n",
    "\n",
    "csv.store(df, dummy_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_metadata = {\n",
    "    'sensor'            : 'HAN24',\n",
    "    'element'           : 'A02',\n",
    "    'fluid'             : 'beer',\n",
    "}\n",
    "csv.store(df, dummy_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from .txt or .csv files\n",
    "\n",
    "### Input File\n",
    "\n",
    "Requires a text file with at least 2 columns.\n",
    "(They don't need to be named in the file)\n",
    "\n",
    "[wavelength]\t[transmission data 1]\t...[transmission data n (optional)]\n",
    "\n",
    "The default is for tab separation, but can be specified with:\n",
    "\n",
    "separator = '\\t'\n",
    "\n",
    "### Regex\n",
    "A regex must be provided to identify these metadata fields from the filename:\n",
    "* sensor\n",
    "* element\n",
    "* fluid\n",
    "\n",
    "Optional, will be preserved in the metadata:\n",
    "* rotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder containing text/csv files to import\n",
    "# import_dir = \"/Users/calum/git/Glasgow/sampleData/Beer x Bitter\"\n",
    "import_dir = \"/Users/calum/git/Glasgow/sampleData/combined\"\n",
    "\n",
    "# Construct a regex to extract metadata from the filename\n",
    "# example 'HAN24_Sensor9_BeerBitter3_Rotation2.txt'\n",
    "regex = '(?P<sensor>.+)_Sensor(?P<element>.+)_(?P<fluid>.+)_Rotation(?P<rotation>.+).txt'\n",
    "\n",
    "h5.import_dir_to_hdf(import_dir, regex, filename, append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect an HDF5 file by metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5.inspect('test.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of searching by metadata\n",
    "\n",
    "filter_by_metadata() returns a list of h5 nodes that match the\n",
    "criteria.\n",
    "\n",
    "It can search a full h5 file, or if a nodelist is provided, it will work from\n",
    "that.\n",
    "\n",
    "Search criteria must include a metadata key, and can optionally include a\n",
    "metadata value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e01 = h5.filter_by_metadata(filename, 'element', \"01\")\n",
    "e01_BeerBitter1 = h5.filter_by_metadata(filename, 'fluid', \"BeerBitter1\", nodelist=e01)\n",
    "\n",
    "print(e01_BeerBitter1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Table\n",
    "\n",
    "export_dataframes() requires a list of measurements to export\n",
    "\n",
    "e.g. by filtering for nodes with 'HAN24' in the 'sensor' metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = h5.filter_by_metadata(filename, 'sensor', 'HAN24')\n",
    "export = h5.export_dataframes(filename, measurements, outfile=None)\n",
    "display(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "dir = \"/Users/calum/git/Glasgow/sampleData/Beer x Bitter\"\n",
    "testfile = \"HAN24_Sensor10_BeerBitter1_Rotation1.txt\"\n",
    "df = pd.read_csv(os.path.join(dir, testfile), sep='\\t')\n",
    "\n",
    "#label columns\n",
    "reps = len(df.columns)-1\n",
    "col_names = ['wavelength']\n",
    "for r in range(reps):\n",
    "\tcol_names.append(F\"rep{r+1}\")\n",
    "df.columns = col_names\n",
    "df\n",
    "\n",
    "def filter_df(df, wl_min, wl_max, resample):\n",
    "\n",
    "    df = df.loc[lambda dfn: dfn['wavelength'] > wl_min-1, :]\n",
    "    df = df.loc[lambda dfn: dfn['wavelength'] < wl_max+1, :]\n",
    "\n",
    "    wavel_new = np.arange(wl_min, wl_max, resample)\n",
    "    result = {}\n",
    "    for col in df:\n",
    "        if col == 'wavelength':\n",
    "            result[col] = wavel_new\n",
    "        else: \n",
    "            maxval = df[col].max()\n",
    "            df[col] = df[col] / maxval\n",
    "            f = interp1d(df['wavelength'], df[col], 'linear')\n",
    "        \n",
    "            result[col] = f(wavel_new)\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "\n",
    "df = filter_df(df, wl_min=540, wl_max=730, resample=0.3)\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f31154455c617200f6006f2a223dcbadc31d7b83ab982d3aca62bb7283f030fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dw': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
